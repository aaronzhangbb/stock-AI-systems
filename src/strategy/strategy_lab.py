# -*- coding: utf-8 -*-
"""
ç­–ç•¥å‘ç°å®éªŒå®¤ - å¤šç»´åº¦ç­–ç•¥åˆ†æå¼•æ“
Strategy Discovery Lab

æ ¸å¿ƒåŠŸèƒ½:
  1. å¤šç»´åº¦è‚¡ç¥¨åˆ†ç»„ (è¡Œä¸š/å¸‚å€¼/æ³¢åŠ¨ç‡/ä»·æ ¼/è¶‹åŠ¿/å¤§ç›˜ç¯å¢ƒ)
  2. æ‰¹é‡ç­–ç•¥å›æµ‹ (å¯¹æ¯ä¸ªåˆ†ç»„è¿è¡Œæ‰€æœ‰AIç­–ç•¥)
  3. æ€§èƒ½çŸ©é˜µç”Ÿæˆ (ç»´åº¦ Ã— ç­–ç•¥ çš„å›æµ‹çŸ©é˜µ)
  4. å‚æ•°ä¼˜åŒ– (è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜ç­–ç•¥å‚æ•°)
  5. MLæ¨¡å¼å‘ç° (æŒ‰åˆ†ç»„æŒ–æ˜æ–°è§„åˆ™)
  6. å¤§ç›˜ç¯å¢ƒè¯†åˆ« (ç‰›/ç†Š/éœ‡è¡å¸‚åˆ’åˆ†)
"""

import sqlite3
import pandas as pd
import numpy as np
import os
import sys
import json
from datetime import datetime, timedelta
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from src.data.data_cache import DataCache
from src.data.stock_pool import StockPool
from src.strategy.ai_strategies import AI_STRATEGIES, compute_ai_features

# ============================================================
# å¸¸é‡
# ============================================================
LAB_DB_PATH = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'strategy_lab.db')

DIMENSIONS = {
    'industry': {'name': 'è¡Œä¸šæ¿å—', 'icon': 'ğŸ­', 'desc': 'æŒ‰ç”³ä¸‡è¡Œä¸šæ¿å—åˆ†ç»„ï¼Œå‘ç°ä¸åŒè¡Œä¸šçš„æœ€ä¼˜ç­–ç•¥'},
    'market_cap': {'name': 'å¸‚å€¼è§„æ¨¡', 'icon': 'ğŸ“Š', 'desc': 'æŒ‰å¸‚å€¼åˆ†ä¸ºå¤§ç›˜/ä¸­ç›˜/å°ç›˜ï¼Œåˆ†æè§„æ¨¡æ•ˆåº”'},
    'volatility': {'name': 'æ³¢åŠ¨ç‡', 'icon': 'ğŸ“ˆ', 'desc': 'æŒ‰å†å²æ³¢åŠ¨ç‡åˆ†ç»„ï¼Œé«˜æ³¢åŠ¨vsä½æ³¢åŠ¨ç­–ç•¥è¡¨ç°'},
    'price_range': {'name': 'ä»·æ ¼åŒºé—´', 'icon': 'ğŸ’°', 'desc': 'æŒ‰è‚¡ä»·åˆ†ç»„ï¼Œä¸åŒä»·ä½ç­–ç•¥æ•ˆæœå·®å¼‚'},
    'trend': {'name': 'è¶‹åŠ¿çŠ¶æ€', 'icon': 'ğŸ“', 'desc': 'ä¸Šå‡/ä¸‹é™/éœ‡è¡è¶‹åŠ¿ä¸‹çš„ç­–ç•¥è¡¨ç°'},
    'market_regime': {'name': 'å¤§ç›˜ç¯å¢ƒ', 'icon': 'ğŸŒ', 'desc': 'ç‰›å¸‚/ç†Šå¸‚/éœ‡è¡å¸‚ä¸­ç­–ç•¥æ•ˆæœå¯¹æ¯”'},
}

# è¡Œä¸šâ†’é£æ ¼æ˜ å°„ï¼ˆç²¾ç®€ç‰ˆï¼Œç”¨äºå¿«é€Ÿåˆ†ç±»ï¼‰
INDUSTRY_STYLE_MAP = {
    'é“¶è¡Œ': 'A-å¤§ç›˜é‡‘è', 'éé“¶é‡‘è': 'A-å¤§ç›˜é‡‘è', 'æˆ¿åœ°äº§': 'A-å¤§ç›˜é‡‘è',
    'å…¬ç”¨äº‹ä¸š': 'A-å¤§ç›˜é‡‘è', 'äº¤é€šè¿è¾“': 'A-å¤§ç›˜é‡‘è', 'å»ºç­‘è£…é¥°': 'A-å¤§ç›˜é‡‘è',
    'ç”µå­': 'B-ç§‘æŠ€æˆé•¿', 'è®¡ç®—æœº': 'B-ç§‘æŠ€æˆé•¿', 'é€šä¿¡': 'B-ç§‘æŠ€æˆé•¿',
    'ä¼ åª’': 'B-ç§‘æŠ€æˆé•¿', 'å›½é˜²å†›å·¥': 'B-ç§‘æŠ€æˆé•¿',
    'é£Ÿå“é¥®æ–™': 'C-æ¶ˆè´¹åŒ»è¯', 'åŒ»è¯ç”Ÿç‰©': 'C-æ¶ˆè´¹åŒ»è¯', 'å®¶ç”¨ç”µå™¨': 'C-æ¶ˆè´¹åŒ»è¯',
    'ç¾å®¹æŠ¤ç†': 'C-æ¶ˆè´¹åŒ»è¯', 'å•†è´¸é›¶å”®': 'C-æ¶ˆè´¹åŒ»è¯', 'ç¤¾ä¼šæœåŠ¡': 'C-æ¶ˆè´¹åŒ»è¯',
    'çººç»‡æœé¥°': 'C-æ¶ˆè´¹åŒ»è¯', 'è½»å·¥åˆ¶é€ ': 'C-æ¶ˆè´¹åŒ»è¯', 'å†œæ—ç‰§æ¸”': 'C-æ¶ˆè´¹åŒ»è¯',
    'åŸºç¡€åŒ–å·¥': 'D-å‘¨æœŸèµ„æº', 'æœ‰è‰²é‡‘å±': 'D-å‘¨æœŸèµ„æº', 'é’¢é“': 'D-å‘¨æœŸèµ„æº',
    'ç…¤ç‚­': 'D-å‘¨æœŸèµ„æº', 'çŸ³æ²¹çŸ³åŒ–': 'D-å‘¨æœŸèµ„æº', 'å»ºç­‘ææ–™': 'D-å‘¨æœŸèµ„æº',
    'æœºæ¢°è®¾å¤‡': 'E-åˆ¶é€ è£…å¤‡', 'ç”µåŠ›è®¾å¤‡': 'E-åˆ¶é€ è£…å¤‡', 'æ±½è½¦': 'E-åˆ¶é€ è£…å¤‡',
    'ç¯ä¿': 'E-åˆ¶é€ è£…å¤‡', 'ç»¼åˆ': 'E-åˆ¶é€ è£…å¤‡',
}


# ============================================================
# ç­–ç•¥å®éªŒå®¤ä¸»ç±»
# ============================================================
class StrategyLab:
    """å¤šç»´åº¦ç­–ç•¥å‘ç°å®éªŒå®¤"""

    def __init__(self, lab_db_path=None):
        self.cache = DataCache()
        self.pool = StockPool()
        self.lab_db = lab_db_path or LAB_DB_PATH
        self._init_lab_db()

    def _init_lab_db(self):
        """åˆå§‹åŒ–å®éªŒå®¤ç»“æœæ•°æ®åº“"""
        os.makedirs(os.path.dirname(self.lab_db), exist_ok=True)
        conn = sqlite3.connect(self.lab_db)
        conn.execute('''
            CREATE TABLE IF NOT EXISTS lab_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                dimension TEXT NOT NULL,
                group_name TEXT NOT NULL,
                strategy_id TEXT NOT NULL,
                strategy_name TEXT NOT NULL,
                win_rate REAL, avg_return REAL, sharpe REAL,
                max_drawdown REAL, profit_loss_ratio REAL,
                trades INTEGER, avg_win REAL, avg_lose REAL,
                stock_count INTEGER, sample_size INTEGER,
                created_at TEXT NOT NULL,
                UNIQUE(dimension, group_name, strategy_id, created_at)
            )
        ''')
        conn.execute('''
            CREATE TABLE IF NOT EXISTS lab_runs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                dimension TEXT NOT NULL,
                status TEXT DEFAULT 'running',
                total_groups INTEGER, completed_groups INTEGER DEFAULT 0,
                total_stocks INTEGER DEFAULT 0, sample_per_group INTEGER,
                started_at TEXT NOT NULL, completed_at TEXT,
                params TEXT
            )
        ''')
        conn.execute('''
            CREATE TABLE IF NOT EXISTS param_optimization (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                dimension TEXT, group_name TEXT,
                strategy_base TEXT, param_name TEXT,
                param_value REAL, win_rate REAL, sharpe REAL,
                avg_return REAL, trades INTEGER,
                created_at TEXT NOT NULL
            )
        ''')
        conn.commit()
        conn.close()

    # ============================================================
    # æ ¸å¿ƒ: è‚¡ç¥¨åˆ†ç»„
    # ============================================================
    def get_stock_groups(self, dimension: str, max_per_group: int = 50) -> dict:
        """
        æŒ‰æŒ‡å®šç»´åº¦å°†è‚¡ç¥¨åˆ†ç»„

        å‚æ•°:
            dimension: ç»´åº¦åç§° (industry/market_cap/volatility/price_range/trend/market_regime)
            max_per_group: æ¯ç»„æœ€å¤§é‡‡æ ·æ•°

        è¿”å›:
            dict: {group_name: [(stock_code, stock_name), ...]}
        """
        # è·å–æ‰€æœ‰å·²ç¼“å­˜çš„è‚¡ç¥¨ï¼Œå¹¶è¿‡æ»¤æ‰ä¸å¯äº¤æ˜“çš„
        cached = self.cache.get_all_cached_stocks()
        if cached.empty:
            return {}

        # ä»è‚¡ç¥¨æ± è·å–å¯äº¤æ˜“åˆ—è¡¨ï¼Œè¿‡æ»¤æ‰ST/Bè‚¡/åŒ—äº¤æ‰€ç­‰
        try:
            tradeable_df = self.pool.get_tradeable_stocks()
            if not tradeable_df.empty:
                tradeable_codes = set(tradeable_df['stock_code'].values)
                cached = cached[cached['stock_code'].isin(tradeable_codes)]
                if cached.empty:
                    return {}
        except (AttributeError, Exception):
            pass  # å¦‚æœæ–¹æ³•ä¸å­˜åœ¨ï¼Œä½¿ç”¨å…¨éƒ¨ç¼“å­˜è‚¡ç¥¨

        if dimension == 'industry':
            return self._group_by_industry(cached, max_per_group)
        elif dimension == 'market_cap':
            return self._group_by_market_cap(cached, max_per_group)
        elif dimension == 'volatility':
            return self._group_by_volatility(cached, max_per_group)
        elif dimension == 'price_range':
            return self._group_by_price_range(cached, max_per_group)
        elif dimension == 'trend':
            return self._group_by_trend(cached, max_per_group)
        elif dimension == 'market_regime':
            return self._group_by_market_regime(cached, max_per_group)
        else:
            return {}

    def _group_by_industry(self, cached_df, max_per_group):
        """æŒ‰è¡Œä¸šæ¿å—åˆ†ç»„"""
        groups = {}
        boards = self.pool.get_industry_boards()
        if boards.empty:
            return groups

        # ç”¨é£æ ¼åˆ†ç±»ä»£æ›¿è¿‡å¤šçš„ç»†åˆ†è¡Œä¸š
        style_stocks = defaultdict(list)
        for _, board in boards.iterrows():
            bname = board['board_name']
            style = INDUSTRY_STYLE_MAP.get(bname, 'F-å…¶ä»–')
            try:
                stocks = self.pool.get_tradeable_stocks_by_board(bname)
            except AttributeError:
                stocks = self.pool.get_stocks_by_board(bname)
            for _, stk in stocks.iterrows():
                code = stk['stock_code']
                if code in cached_df['stock_code'].values:
                    style_stocks[style].append((code, stk.get('stock_name', '')))

        # åŒæ—¶æä¾›ç»†åˆ†è¡Œä¸šåˆ†ç»„ï¼ˆå–å‰15ä¸ªå¤§è¡Œä¸šï¼‰
        top_boards = boards.nlargest(15, 'stock_count')
        for _, board in top_boards.iterrows():
            bname = board['board_name']
            try:
                stocks = self.pool.get_tradeable_stocks_by_board(bname)
            except AttributeError:
                stocks = self.pool.get_stocks_by_board(bname)
            stock_list = []
            for _, stk in stocks.iterrows():
                code = stk['stock_code']
                if code in cached_df['stock_code'].values:
                    stock_list.append((code, stk.get('stock_name', '')))
            if len(stock_list) >= 10:
                key = f'è¡Œä¸š-{bname}'
                if len(stock_list) > max_per_group:
                    stock_list = self._random_sample(stock_list, max_per_group)
                groups[key] = stock_list

        # é£æ ¼åˆ†ç»„
        for style, stock_list in style_stocks.items():
            if len(stock_list) >= 5:
                key = f'é£æ ¼-{style}'
                if len(stock_list) > max_per_group:
                    stock_list = self._random_sample(stock_list, max_per_group)
                groups[key] = stock_list

        return groups

    def _group_by_market_cap(self, cached_df, max_per_group):
        """æŒ‰å¸‚å€¼è§„æ¨¡åˆ†ç»„ï¼ˆç”¨æœ€æ–°ä»·æ ¼Ã—æ—¥å‡æˆäº¤é‡è¿‘ä¼¼ï¼‰"""
        groups = {'å¤§ç›˜è‚¡(é«˜æµåŠ¨æ€§)': [], 'ä¸­ç›˜è‚¡(ä¸­æµåŠ¨æ€§)': [], 'å°ç›˜è‚¡(ä½æµåŠ¨æ€§)': []}
        stock_scores = []

        for _, row in cached_df.iterrows():
            code = row['stock_code']
            name = row.get('stock_name', '')
            try:
                df = self.cache.load_kline(code)
                if df is not None and len(df) >= 30:
                    recent = df.tail(30)
                    avg_amount = (recent['close'] * recent['volume']).mean()
                    stock_scores.append((code, name, avg_amount))
            except Exception:
                continue

        if not stock_scores:
            return groups

        stock_scores.sort(key=lambda x: x[2], reverse=True)
        n = len(stock_scores)
        t1 = n // 3
        t2 = 2 * n // 3

        large = [(s[0], s[1]) for s in stock_scores[:t1]]
        mid = [(s[0], s[1]) for s in stock_scores[t1:t2]]
        small = [(s[0], s[1]) for s in stock_scores[t2:]]

        groups['å¤§ç›˜è‚¡(é«˜æµåŠ¨æ€§)'] = self._random_sample(large, max_per_group) if len(large) > max_per_group else large
        groups['ä¸­ç›˜è‚¡(ä¸­æµåŠ¨æ€§)'] = self._random_sample(mid, max_per_group) if len(mid) > max_per_group else mid
        groups['å°ç›˜è‚¡(ä½æµåŠ¨æ€§)'] = self._random_sample(small, max_per_group) if len(small) > max_per_group else small

        return {k: v for k, v in groups.items() if v}

    def _group_by_volatility(self, cached_df, max_per_group):
        """æŒ‰60æ—¥å¹´åŒ–æ³¢åŠ¨ç‡åˆ†ç»„"""
        groups = {'ä½æ³¢åŠ¨(<25%)': [], 'ä¸­æ³¢åŠ¨(25-50%)': [], 'é«˜æ³¢åŠ¨(50-80%)': [], 'æé«˜æ³¢åŠ¨(>80%)': []}
        for _, row in cached_df.iterrows():
            code = row['stock_code']
            name = row.get('stock_name', '')
            try:
                df = self.cache.load_kline(code)
                if df is not None and len(df) >= 70:
                    ret = df['close'].pct_change().dropna()
                    vol = ret.tail(60).std() * np.sqrt(252) * 100
                    item = (code, name)
                    if vol < 25:
                        groups['ä½æ³¢åŠ¨(<25%)'].append(item)
                    elif vol < 50:
                        groups['ä¸­æ³¢åŠ¨(25-50%)'].append(item)
                    elif vol < 80:
                        groups['é«˜æ³¢åŠ¨(50-80%)'].append(item)
                    else:
                        groups['æé«˜æ³¢åŠ¨(>80%)'].append(item)
            except Exception:
                continue

        for k in groups:
            if len(groups[k]) > max_per_group:
                groups[k] = self._random_sample(groups[k], max_per_group)
        return {k: v for k, v in groups.items() if v}

    def _group_by_price_range(self, cached_df, max_per_group):
        """æŒ‰æœ€æ–°æ”¶ç›˜ä»·åˆ†ç»„"""
        groups = {'ä½ä»·è‚¡(<10å…ƒ)': [], 'ä¸­ä½ä»·(10-30å…ƒ)': [], 'ä¸­é«˜ä»·(30-80å…ƒ)': [], 'é«˜ä»·è‚¡(>80å…ƒ)': []}
        for _, row in cached_df.iterrows():
            code = row['stock_code']
            name = row.get('stock_name', '')
            try:
                df = self.cache.load_kline(code)
                if df is not None and len(df) >= 10:
                    price = float(df.iloc[-1]['close'])
                    item = (code, name)
                    if price < 10:
                        groups['ä½ä»·è‚¡(<10å…ƒ)'].append(item)
                    elif price < 30:
                        groups['ä¸­ä½ä»·(10-30å…ƒ)'].append(item)
                    elif price < 80:
                        groups['ä¸­é«˜ä»·(30-80å…ƒ)'].append(item)
                    else:
                        groups['é«˜ä»·è‚¡(>80å…ƒ)'].append(item)
            except Exception:
                continue

        for k in groups:
            if len(groups[k]) > max_per_group:
                groups[k] = self._random_sample(groups[k], max_per_group)
        return {k: v for k, v in groups.items() if v}

    def _group_by_trend(self, cached_df, max_per_group):
        """æŒ‰å½“å‰è¶‹åŠ¿çŠ¶æ€åˆ†ç»„ï¼ˆåŸºäºMA20/MA60å…³ç³»ï¼‰"""
        groups = {'ä¸Šå‡è¶‹åŠ¿': [], 'ä¸‹é™è¶‹åŠ¿': [], 'æ¨ªç›˜éœ‡è¡': []}
        for _, row in cached_df.iterrows():
            code = row['stock_code']
            name = row.get('stock_name', '')
            try:
                df = self.cache.load_kline(code)
                if df is not None and len(df) >= 65:
                    close = df['close']
                    ma20 = close.rolling(20).mean().iloc[-1]
                    ma60 = close.rolling(60).mean().iloc[-1]
                    ma20_slope = (close.rolling(20).mean().iloc[-1] - close.rolling(20).mean().iloc[-6]) / close.rolling(20).mean().iloc[-6]
                    last_price = float(close.iloc[-1])
                    item = (code, name)
                    if last_price > ma20 > ma60 and ma20_slope > 0.01:
                        groups['ä¸Šå‡è¶‹åŠ¿'].append(item)
                    elif last_price < ma20 < ma60 or ma20_slope < -0.02:
                        groups['ä¸‹é™è¶‹åŠ¿'].append(item)
                    else:
                        groups['æ¨ªç›˜éœ‡è¡'].append(item)
            except Exception:
                continue

        for k in groups:
            if len(groups[k]) > max_per_group:
                groups[k] = self._random_sample(groups[k], max_per_group)
        return {k: v for k, v in groups.items() if v}

    def _group_by_market_regime(self, cached_df, max_per_group):
        """
        æŒ‰å¤§ç›˜ç¯å¢ƒåˆ†ç»„ â€” ä¸åˆ†è‚¡ç¥¨ï¼Œè€Œæ˜¯æŠŠæ—¶é—´æ®µåˆ†ä¸ºç‰›/ç†Š/éœ‡è¡
        å¯¹æ‰€æœ‰è‚¡ç¥¨åœ¨ä¸åŒæ—¶é—´æ®µè¿è¡Œç­–ç•¥
        """
        # ç”¨æ²ªæ·±300/ä¸Šè¯æŒ‡æ•°çš„è¡¨ç°æ¥åˆ¤æ–­å¤§ç›˜ç¯å¢ƒ
        # ç®€å•æ–¹æ³•ï¼šæŠŠå†å²æ•°æ®æŒ‰å­£åº¦åˆ’åˆ†ï¼Œçœ‹æ¯ä¸ªå­£åº¦æŒ‡æ•°æ¶¨è·Œ
        # ç”±äºæˆ‘ä»¬æ²¡æœ‰æŒ‡æ•°æ•°æ®ç¼“å­˜ï¼Œç”¨æ‰€æœ‰ç¼“å­˜è‚¡ç¥¨çš„ä¸­ä½æ•°æ¶¨è·Œæ¥è¿‘ä¼¼
        groups = {
            'ç‰›å¸‚é˜¶æ®µ(å¤§ç›˜ä¸Šæ¶¨>10%)': [],
            'ç†Šå¸‚é˜¶æ®µ(å¤§ç›˜ä¸‹è·Œ>10%)': [],
            'éœ‡è¡é˜¶æ®µ(å¤§ç›˜Â±10%)': [],
        }
        # æ‰€æœ‰ç¼“å­˜è‚¡ç¥¨å³ä¸ºåˆ†æå¯¹è±¡ï¼ŒæŒ‰æ—¶é—´æ®µæ‹†åˆ†åœ¨å›æµ‹ä¸­å¤„ç†
        all_stocks = [(row['stock_code'], row.get('stock_name', '')) for _, row in cached_df.iterrows()]
        if len(all_stocks) > max_per_group:
            all_stocks = self._random_sample(all_stocks, max_per_group)
        # æ‰€æœ‰è‚¡ç¥¨æ”¾åœ¨åŒä¸€ç»„ï¼Œä½†å›æµ‹æ—¶æŒ‰æ—¶æ®µæ‹†åˆ†
        groups['ç‰›å¸‚é˜¶æ®µ(å¤§ç›˜ä¸Šæ¶¨>10%)'] = all_stocks
        groups['ç†Šå¸‚é˜¶æ®µ(å¤§ç›˜ä¸‹è·Œ>10%)'] = all_stocks
        groups['éœ‡è¡é˜¶æ®µ(å¤§ç›˜Â±10%)'] = all_stocks
        return groups

    @staticmethod
    def _random_sample(lst, n):
        """éšæœºé‡‡æ ·"""
        np.random.seed(42)
        indices = np.random.choice(len(lst), size=min(n, len(lst)), replace=False)
        return [lst[i] for i in indices]

    # ============================================================
    # æ ¸å¿ƒ: ç­–ç•¥å›æµ‹
    # ============================================================
    def backtest_strategy_on_group(self, stock_list, strategy, hold_days=10,
                                   regime=None, cost_rate=0.002):
        """
        åœ¨ä¸€ç»„è‚¡ç¥¨ä¸Šå›æµ‹å•ä¸ªç­–ç•¥

        å‚æ•°:
            stock_list: [(code, name), ...]
            strategy: AI_STRATEGIESä¸­çš„ç­–ç•¥dict
            hold_days: æŒæœ‰å¤©æ•°
            regime: å¸‚åœºç¯å¢ƒè¿‡æ»¤ ('bull'/'bear'/'sideways'/None)
            cost_rate: äº¤æ˜“æˆæœ¬ç‡

        è¿”å›:
            dict: å›æµ‹æŒ‡æ ‡
        """
        all_returns = []

        for code, name in stock_list:
            try:
                df = self.cache.load_kline(code)
                if df is None or len(df) < 80:
                    continue

                data = compute_ai_features(df)
                if data.empty:
                    continue

                # å¸‚åœºç¯å¢ƒè¿‡æ»¤
                if regime:
                    data = self._filter_by_regime(data, regime)
                    if len(data) < 80:
                        continue

                # æ£€æŸ¥ç­–ç•¥è§¦å‘æ¡ä»¶
                for i in range(60, len(data) - hold_days):
                    row = data.iloc[i]
                    triggered = True
                    for feat, op, val in strategy['conditions']:
                        if feat not in data.columns:
                            triggered = False
                            break
                        fv = row[feat]
                        if pd.isna(fv):
                            triggered = False
                            break
                        if op == '>=' and not (fv >= val):
                            triggered = False
                        elif op == '<=' and not (fv <= val):
                            triggered = False
                        elif op == '>' and not (fv > val):
                            triggered = False
                        elif op == '<' and not (fv < val):
                            triggered = False
                    if triggered:
                        buy_price = float(data.iloc[i]['close'])
                        sell_price = float(data.iloc[i + hold_days]['close'])
                        ret = (sell_price - buy_price) / buy_price - cost_rate
                        all_returns.append(ret)
            except Exception:
                continue

        return self._compute_metrics(all_returns, stock_list)

    def _filter_by_regime(self, data, regime):
        """æŒ‰å¸‚åœºç¯å¢ƒè¿‡æ»¤æ•°æ®è¡Œ"""
        if 'close' not in data.columns:
            return data

        # è®¡ç®—60æ—¥æ»šåŠ¨æ”¶ç›Šæ¥åˆ¤æ–­å¤§ç›˜ç¯å¢ƒ
        data = data.copy()
        data['rolling_ret_60'] = data['close'].pct_change(60)

        if regime == 'bull':
            return data[data['rolling_ret_60'] > 0.10].copy()
        elif regime == 'bear':
            return data[data['rolling_ret_60'] < -0.10].copy()
        elif regime == 'sideways':
            return data[(data['rolling_ret_60'] >= -0.10) & (data['rolling_ret_60'] <= 0.10)].copy()
        return data

    @staticmethod
    def _compute_metrics(returns_list, stock_list):
        """ä»æ”¶ç›Šåˆ—è¡¨è®¡ç®—å›æµ‹æŒ‡æ ‡"""
        if not returns_list or len(returns_list) < 5:
            return {
                'win_rate': 0, 'avg_return': 0, 'sharpe': 0,
                'max_drawdown': 0, 'profit_loss_ratio': 0,
                'trades': len(returns_list), 'avg_win': 0, 'avg_lose': 0,
                'stock_count': len(stock_list), 'sample_size': len(returns_list),
            }

        arr = np.array(returns_list) * 100  # è½¬ä¸ºç™¾åˆ†æ¯”
        wins = arr[arr > 0]
        losses = arr[arr <= 0]

        win_rate = len(wins) / len(arr) * 100 if len(arr) > 0 else 0
        avg_ret = float(np.mean(arr))
        avg_win = float(np.mean(wins)) if len(wins) > 0 else 0
        avg_lose = float(np.mean(losses)) if len(losses) > 0 else 0
        pl_ratio = abs(avg_win / avg_lose) if avg_lose != 0 else 0

        # å¤æ™®æ¯”ç‡ (å¹´åŒ–)
        if np.std(arr) > 0:
            sharpe = float(np.mean(arr) / np.std(arr) * np.sqrt(252 / 10))
        else:
            sharpe = 0

        # æœ€å¤§å›æ’¤
        cum = np.cumsum(arr)
        peak = np.maximum.accumulate(cum)
        dd = cum - peak
        max_dd = float(np.min(dd)) if len(dd) > 0 else 0

        return {
            'win_rate': round(win_rate, 2),
            'avg_return': round(avg_ret, 2),
            'sharpe': round(sharpe, 2),
            'max_drawdown': round(max_dd, 2),
            'profit_loss_ratio': round(pl_ratio, 2),
            'trades': len(arr),
            'avg_win': round(avg_win, 2),
            'avg_lose': round(avg_lose, 2),
            'stock_count': len(stock_list),
            'sample_size': len(arr),
        }

    # ============================================================
    # æ ¸å¿ƒ: ç»´åº¦åˆ†æï¼ˆæ‰¹é‡è¿è¡Œï¼‰
    # ============================================================
    def run_dimension_analysis(self, dimension: str, max_per_group: int = 40,
                                hold_days: int = 10, strategies=None,
                                progress_callback=None):
        """
        å¯¹æŒ‡å®šç»´åº¦è¿›è¡Œå…¨é¢ç­–ç•¥åˆ†æ

        å‚æ•°:
            dimension: ç»´åº¦å
            max_per_group: æ¯ç»„é‡‡æ ·è‚¡ç¥¨æ•°
            hold_days: æŒæœ‰å¤©æ•°
            strategies: ç­–ç•¥åˆ—è¡¨ (é»˜è®¤ç”¨AI_STRATEGIES)
            progress_callback: fn(current, total, group_name, strategy_name)

        è¿”å›:
            dict: {
                'dimension': str,
                'groups': {group_name: group_info},
                'matrix': pd.DataFrame (group Ã— strategy â†’ metrics),
                'best_by_group': {group_name: best_strategy_info},
                'insights': [str, ...],
                'run_id': int,
            }
        """
        if strategies is None:
            strategies = AI_STRATEGIES

        # è·å–åˆ†ç»„
        groups = self.get_stock_groups(dimension, max_per_group)
        if not groups:
            return {'error': 'æ— æ³•è·å–åˆ†ç»„æ•°æ®ï¼Œè¯·ç¡®ä¿å·²ç¼“å­˜å†å²æ•°æ®'}

        # è®°å½•è¿è¡Œ
        run_id = self._log_run_start(dimension, len(groups), max_per_group)

        total_tasks = len(groups) * len(strategies)
        current = 0
        results = {}
        matrix_rows = []

        is_regime = (dimension == 'market_regime')

        for gname, stock_list in groups.items():
            group_results = {}

            # ç¡®å®šå¤§ç›˜ç¯å¢ƒæ ‡è®°
            regime = None
            if is_regime:
                if 'ç‰›å¸‚' in gname:
                    regime = 'bull'
                elif 'ç†Šå¸‚' in gname:
                    regime = 'bear'
                elif 'éœ‡è¡' in gname:
                    regime = 'sideways'

            for strat in strategies:
                current += 1
                if progress_callback:
                    progress_callback(current, total_tasks, gname, strat['name'])

                metrics = self.backtest_strategy_on_group(
                    stock_list, strat, hold_days=hold_days, regime=regime
                )
                group_results[strat['id']] = {
                    'name': strat['name'],
                    'tier': strat['tier'],
                    **metrics,
                }

                # ä¿å­˜åˆ°DB
                self._save_result(dimension, gname, strat, metrics, run_id)

                matrix_rows.append({
                    'åˆ†ç»„': gname,
                    'ç­–ç•¥': strat['name'],
                    'ç­–ç•¥ID': strat['id'],
                    'èƒœç‡': metrics['win_rate'],
                    'æ”¶ç›Š': metrics['avg_return'],
                    'å¤æ™®': metrics['sharpe'],
                    'å›æ’¤': metrics['max_drawdown'],
                    'ç›ˆäºæ¯”': metrics['profit_loss_ratio'],
                    'äº¤æ˜“æ•°': metrics['trades'],
                })

            results[gname] = {
                'stock_count': len(stock_list),
                'strategies': group_results,
            }

        # æ„å»ºçŸ©é˜µDataFrame
        matrix_df = pd.DataFrame(matrix_rows)

        # æ‰¾å‡ºæ¯ä¸ªåˆ†ç»„çš„æœ€ä½³ç­–ç•¥
        best_by_group = {}
        for gname, ginfo in results.items():
            best_strat = None
            best_score = -999
            for sid, sinfo in ginfo['strategies'].items():
                # ç»¼åˆè¯„åˆ† = èƒœç‡Ã—0.4 + å¤æ™®Ã—15 + æ¯ç¬”æ”¶ç›ŠÃ—2
                score = sinfo['win_rate'] * 0.4 + sinfo['sharpe'] * 15 + sinfo['avg_return'] * 2
                if sinfo['trades'] < 10:
                    score *= 0.3  # æ ·æœ¬ä¸è¶³æƒ©ç½š
                if score > best_score:
                    best_score = score
                    best_strat = sinfo
            best_by_group[gname] = best_strat

        # ç”Ÿæˆæ´å¯Ÿ
        insights = self._generate_insights(dimension, results, best_by_group, matrix_df)

        # æ›´æ–°è¿è¡ŒçŠ¶æ€
        self._log_run_complete(run_id, len(groups))

        return {
            'dimension': dimension,
            'dimension_name': DIMENSIONS.get(dimension, {}).get('name', dimension),
            'groups': results,
            'matrix': matrix_df,
            'best_by_group': best_by_group,
            'insights': insights,
            'run_id': run_id,
        }

    # ============================================================
    # å‚æ•°ä¼˜åŒ–
    # ============================================================
    def optimize_parameters(self, stock_list, base_strategy_id='ai_core_01',
                             param_name='threshold', param_range=None,
                             hold_days=10, progress_callback=None):
        """
        å¯¹å•ä¸ªç­–ç•¥è¿›è¡Œå‚æ•°ä¼˜åŒ–

        è¿”å›:
            list[dict]: æ¯ä¸ªå‚æ•°å€¼çš„å›æµ‹ç»“æœ
        """
        base = None
        for s in AI_STRATEGIES:
            if s['id'] == base_strategy_id:
                base = s.copy()
                break
        if base is None:
            return []

        # æ ¹æ®ç­–ç•¥ç±»å‹ç¡®å®šå‚æ•°èŒƒå›´
        if param_range is None:
            conditions = base['conditions']
            # æ‰¾åˆ°ä¸»è¦æ¡ä»¶çš„ä¸‹é™ï¼ˆå¦‚ma30_diff <= -0.0962ï¼‰
            param_range = []
            for feat, op, val in conditions:
                if op == '<=':
                    # åœ¨åŸå§‹å€¼é™„è¿‘æœç´¢
                    for factor in [0.5, 0.7, 0.85, 1.0, 1.15, 1.3, 1.5, 1.8, 2.0]:
                        param_range.append((feat, op, val * factor))

        results = []
        total = len(param_range)
        for i, (feat, op, new_val) in enumerate(param_range):
            if progress_callback:
                progress_callback(i + 1, total, feat, f'{new_val:.4f}')

            # ä¿®æ”¹æ¡ä»¶
            modified = base.copy()
            modified['conditions'] = []
            for f, o, v in base['conditions']:
                if f == feat and o == op:
                    modified['conditions'].append((f, o, new_val))
                else:
                    modified['conditions'].append((f, o, v))

            metrics = self.backtest_strategy_on_group(stock_list, modified, hold_days)
            results.append({
                'param_name': feat,
                'param_op': op,
                'param_value': new_val,
                'original_value': next(v for f, o, v in base['conditions'] if f == feat and o == op),
                **metrics,
            })

        return sorted(results, key=lambda x: x['sharpe'], reverse=True)

    # ============================================================
    # ç»¼åˆåˆ†æï¼ˆä¸€é”®å…¨ç»´åº¦ï¼‰
    # ============================================================
    def run_full_analysis(self, dimensions=None, max_per_group=30,
                           hold_days=10, progress_callback=None):
        """
        è¿è¡Œæ‰€æœ‰ç»´åº¦çš„åˆ†æ

        è¿”å›:
            dict: {dimension: analysis_result}
        """
        if dimensions is None:
            dimensions = ['industry', 'market_cap', 'volatility', 'price_range', 'trend']

        all_results = {}
        total_dims = len(dimensions)

        for idx, dim in enumerate(dimensions):
            if progress_callback:
                progress_callback(idx, total_dims, dim, 'å¼€å§‹åˆ†æ...')

            result = self.run_dimension_analysis(
                dim, max_per_group=max_per_group, hold_days=hold_days,
                progress_callback=progress_callback
            )
            all_results[dim] = result

        return all_results

    # ============================================================
    # è·å–å†å²åˆ†æç»“æœ
    # ============================================================
    def get_latest_results(self, dimension: str = None):
        """è·å–æœ€è¿‘ä¸€æ¬¡åˆ†æç»“æœ"""
        conn = sqlite3.connect(self.lab_db)
        if dimension:
            runs = pd.read_sql_query(
                'SELECT * FROM lab_runs WHERE dimension=? AND status="completed" ORDER BY id DESC LIMIT 1',
                conn, params=[dimension])
        else:
            runs = pd.read_sql_query(
                'SELECT * FROM lab_runs WHERE status="completed" ORDER BY id DESC LIMIT 1', conn)

        if runs.empty:
            conn.close()
            return None

        run = runs.iloc[0]
        dim = run['dimension']
        created_at = run['started_at']

        results_df = pd.read_sql_query(
            'SELECT * FROM lab_results WHERE dimension=? AND created_at >= ?',
            conn, params=[dim, created_at])
        conn.close()

        if results_df.empty:
            return None

        # é‡å»ºmatrix
        matrix_rows = []
        for _, r in results_df.iterrows():
            matrix_rows.append({
                'åˆ†ç»„': r['group_name'],
                'ç­–ç•¥': r['strategy_name'],
                'ç­–ç•¥ID': r['strategy_id'],
                'èƒœç‡': r['win_rate'],
                'æ”¶ç›Š': r['avg_return'],
                'å¤æ™®': r['sharpe'],
                'å›æ’¤': r['max_drawdown'],
                'ç›ˆäºæ¯”': r['profit_loss_ratio'],
                'äº¤æ˜“æ•°': r['trades'],
            })

        matrix_df = pd.DataFrame(matrix_rows)

        # æ‰¾æœ€ä½³
        best_by_group = {}
        for gname in matrix_df['åˆ†ç»„'].unique():
            gdf = matrix_df[matrix_df['åˆ†ç»„'] == gname]
            if not gdf.empty:
                best_idx = (gdf['èƒœç‡'] * 0.4 + gdf['å¤æ™®'] * 15 + gdf['æ”¶ç›Š'] * 2).idxmax()
                best_row = gdf.loc[best_idx]
                best_by_group[gname] = {
                    'name': best_row['ç­–ç•¥'],
                    'win_rate': best_row['èƒœç‡'],
                    'sharpe': best_row['å¤æ™®'],
                    'avg_return': best_row['æ”¶ç›Š'],
                    'trades': best_row['äº¤æ˜“æ•°'],
                }

        insights = self._generate_insights_from_matrix(dim, matrix_df, best_by_group)

        return {
            'dimension': dim,
            'dimension_name': DIMENSIONS.get(dim, {}).get('name', dim),
            'matrix': matrix_df,
            'best_by_group': best_by_group,
            'insights': insights,
            'run_info': run.to_dict(),
        }

    def get_all_run_history(self):
        """è·å–æ‰€æœ‰è¿è¡Œå†å²"""
        conn = sqlite3.connect(self.lab_db)
        df = pd.read_sql_query(
            'SELECT * FROM lab_runs ORDER BY id DESC LIMIT 50', conn)
        conn.close()
        return df

    # ============================================================
    # æ´å¯Ÿç”Ÿæˆ
    # ============================================================
    def _generate_insights(self, dimension, results, best_by_group, matrix_df):
        """æ ¹æ®åˆ†æç»“æœç”Ÿæˆæ´å¯Ÿ"""
        insights = []

        if matrix_df.empty:
            return ['æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆæ´å¯Ÿ']

        # 1. æ•´ä½“æœ€ä½³ç­–ç•¥
        if not matrix_df.empty and matrix_df['äº¤æ˜“æ•°'].sum() > 0:
            valid = matrix_df[matrix_df['äº¤æ˜“æ•°'] >= 10]
            if not valid.empty:
                best_idx = valid['å¤æ™®'].idxmax()
                best = valid.loc[best_idx]
                insights.append(
                    f"ğŸ† æ•´ä½“æœ€ä¼˜ï¼šã€Œ{best['ç­–ç•¥']}ã€åœ¨ã€Œ{best['åˆ†ç»„']}ã€ä¸­è¡¨ç°æœ€ä½³ "
                    f"(èƒœç‡{best['èƒœç‡']:.1f}%, å¤æ™®{best['å¤æ™®']:.2f}, æ”¶ç›Š{best['æ”¶ç›Š']:.2f}%)"
                )

        # 2. æŒ‰åˆ†ç»„æ‰¾å·®å¼‚
        group_best_rates = [(g, info['name'], info.get('win_rate', 0))
                            for g, info in best_by_group.items() if info]
        if len(group_best_rates) >= 2:
            group_best_rates.sort(key=lambda x: x[2], reverse=True)
            top = group_best_rates[0]
            bot = group_best_rates[-1]
            if top[2] - bot[2] > 5:
                insights.append(
                    f"ğŸ“Š åˆ†ç»„å·®å¼‚ï¼šã€Œ{top[0]}ã€æœ€ä½³èƒœç‡{top[2]:.1f}% vs ã€Œ{bot[0]}ã€æœ€ä½{bot[2]:.1f}%ï¼Œ"
                    f"å·®è·{top[2]-bot[2]:.1f}ä¸ªç™¾åˆ†ç‚¹"
                )

        # 3. ç­–ç•¥æ™®é€‚æ€§
        strat_counts = defaultdict(list)
        for g, info in best_by_group.items():
            if info:
                strat_counts[info['name']].append(g)
        if strat_counts:
            most_common = max(strat_counts.items(), key=lambda x: len(x[1]))
            insights.append(
                f"ğŸ”„ æœ€æ™®é€‚ç­–ç•¥ï¼šã€Œ{most_common[0]}ã€åœ¨ {len(most_common[1])}/{len(best_by_group)} ä¸ªåˆ†ç»„ä¸­è¡¨ç°æœ€å¥½"
            )

        # 4. æ ·æœ¬å……è¶³æ€§
        low_sample = matrix_df[matrix_df['äº¤æ˜“æ•°'] < 20]
        if len(low_sample) > 0:
            insights.append(
                f"âš ï¸ æ³¨æ„ï¼š{len(low_sample)} é¡¹æµ‹è¯•äº¤æ˜“æ¬¡æ•° < 20ï¼Œç»“æœå¯é æ€§æœ‰é™"
            )

        # 5. é«˜èƒœç‡å‘ç°
        high_wr = matrix_df[(matrix_df['èƒœç‡'] > 70) & (matrix_df['äº¤æ˜“æ•°'] >= 20)]
        if not high_wr.empty:
            insights.append(
                f"ğŸ¯ é«˜èƒœç‡å‘ç°ï¼š{len(high_wr)} é¡¹ç»„åˆèƒœç‡è¶…è¿‡70%ï¼ˆä¸”äº¤æ˜“>=20æ¬¡ï¼‰"
            )

        return insights

    def _generate_insights_from_matrix(self, dimension, matrix_df, best_by_group):
        """ä»çŸ©é˜µæ•°æ®ç”Ÿæˆæ´å¯Ÿï¼ˆç”¨äºç¼“å­˜ç»“æœï¼‰"""
        return self._generate_insights(dimension, {}, best_by_group, matrix_df)

    # ============================================================
    # æ•°æ®åº“æ“ä½œ
    # ============================================================
    def _log_run_start(self, dimension, total_groups, sample_per_group):
        conn = sqlite3.connect(self.lab_db)
        cursor = conn.cursor()
        cursor.execute(
            'INSERT INTO lab_runs (dimension, status, total_groups, sample_per_group, started_at) VALUES (?,?,?,?,?)',
            (dimension, 'running', total_groups, sample_per_group, datetime.now().isoformat())
        )
        run_id = cursor.lastrowid
        conn.commit()
        conn.close()
        return run_id

    def _log_run_complete(self, run_id, completed_groups):
        conn = sqlite3.connect(self.lab_db)
        conn.execute(
            'UPDATE lab_runs SET status=?, completed_groups=?, completed_at=? WHERE id=?',
            ('completed', completed_groups, datetime.now().isoformat(), run_id)
        )
        conn.commit()
        conn.close()

    def _save_result(self, dimension, group_name, strategy, metrics, run_id):
        conn = sqlite3.connect(self.lab_db)
        try:
            conn.execute('''
                INSERT OR REPLACE INTO lab_results
                (dimension, group_name, strategy_id, strategy_name,
                 win_rate, avg_return, sharpe, max_drawdown, profit_loss_ratio,
                 trades, avg_win, avg_lose, stock_count, sample_size, created_at)
                VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)
            ''', (
                dimension, group_name, strategy['id'], strategy['name'],
                metrics['win_rate'], metrics['avg_return'], metrics['sharpe'],
                metrics['max_drawdown'], metrics['profit_loss_ratio'],
                metrics['trades'], metrics['avg_win'], metrics['avg_lose'],
                metrics['stock_count'], metrics['sample_size'],
                datetime.now().isoformat()
            ))
            conn.commit()
        except Exception:
            pass
        finally:
            conn.close()
